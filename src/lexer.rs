//! âœ… DSLìš© Lexer
//!
//! ì´ ëª¨ë“ˆì€ ì‚¬ìš©ì ì •ì˜ DSL ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” Tokenìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ì—­í• ì„ í•œë‹¤.
//! - ì˜ˆ: input, output, transform, print ë“±ì˜ í‚¤ì›Œë“œ
//! - ë¬¸ìì—´, í•„ë“œ(@key), ì—°ì‚°ì, ì¤‘ê´„í˜¸, í•¨ìˆ˜ í˜¸ì¶œ ë“± ì²˜ë¦¬

use std::iter::Peekable;
use std::str::Chars;

/// âœ… DSLì—ì„œ ì‚¬ìš©í•  í† í° ì •ì˜
#[derive(Debug, Clone, PartialEq)]
pub enum Token {
    // ğŸ”¹ í‚¤ì›Œë“œ
    Input,
    Output,
    Transform,
    Print,

    // ğŸ”¹ ë¦¬í„°ëŸ´ / ì°¸ì¡°
    StringLiteral(String),   // ì˜ˆ: "data.jsonl"
    Identifier(String),      // ì˜ˆ: suffix, line
    Field(String),           // ì˜ˆ: @ë¬¸ì œ
    Number(usize),           // ì˜ˆ: 42

    // ğŸ”¹ ì—°ì‚°ì ë° êµ¬ë¶„ì
    Plus,                    // +
    Equal,                   // =
    Semicolon,              // ;
    LBrace, RBrace,         // {, }
    Dot,                    // .
    LParen, RParen,         // (, )

    // ğŸ”¹ ì£¼ì„
    Comment(String),        // // ë˜ëŠ” /* */ ì£¼ì„

    // ğŸ”¹ ì˜ˆì™¸
    Unknown(char),          // ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì
    EOF,                    // ì…ë ¥ ì¢…ë£Œ
}

/// âœ… ì…ë ¥ ë¬¸ìì—´ì„ ìˆœíšŒí•˜ë©° Tokenì„ ìƒì„±í•˜ëŠ” êµ¬ì¡°ì²´
pub struct Lexer<'a> {
    input: Peekable<Chars<'a>>,
}

impl<'a> Lexer<'a> {
    /// ğŸ”¹ Lexer ìƒì„±ì
    pub fn new(source: &'a str) -> Self {
        Self {
            input: source.chars().peekable(),
        }
    }

    /// ğŸ”¹ ë¬¸ì í•˜ë‚˜ ì½ê¸° (consume)
    fn next_char(&mut self) -> Option<char> {
        self.input.next()
    }

    /// ğŸ”¹ ë‹¤ìŒ ë¬¸ì ë¯¸ë¦¬ë³´ê¸° (peek)
    fn peek_char(&mut self) -> Option<&char> {
        self.input.peek()
    }

    /// ğŸ”¹ ë¬¸ìì—´ ë¦¬í„°ëŸ´ íŒŒì‹± (ì˜ˆ: "...")
    fn read_string(&mut self) -> Token {
        let mut result = String::new();

        while let Some(c) = self.next_char() {
            if c == '"' {
                break;
            }
            result.push(c);
        }

        Token::StringLiteral(result)
    }

    /// ğŸ”¹ @í•„ë“œ ì²˜ë¦¬ (ì˜ˆ: @ë¬¸ì œ)
    fn read_field(&mut self) -> Token {
        let mut name = String::new();

        while let Some(&c) = self.peek_char() {
            if c.is_alphanumeric() || c == '_' {
                name.push(self.next_char().unwrap());
            } else {
                break;
            }
        }

        Token::Field(name)
    }

    /// ğŸ”¹ ì‹ë³„ì / ìˆ«ì / í‚¤ì›Œë“œ íŒŒì‹±
    fn read_identifier_or_number(&mut self, first_char: char) -> Token {
        let mut value = String::new();
        value.push(first_char);

        while let Some(&c) = self.peek_char() {
            if c.is_alphanumeric() || c == '_' {
                value.push(self.next_char().unwrap());
            } else {
                break;
            }
        }

        match value.as_str() {
            "input" => Token::Input,
            "output" => Token::Output,
            "transform" => Token::Transform,
            "print" => Token::Print,
            _ => {
                if let Ok(num) = value.parse::<usize>() {
                    Token::Number(num)
                } else {
                    Token::Identifier(value)
                }
            }
        }
    }

    /// ğŸ”¹ ë¼ì¸ ì£¼ì„ íŒŒì‹± (ì˜ˆ: // ...)
    fn read_line_comment(&mut self) -> Token {
        let mut result = String::new();

        while let Some(&c) = self.peek_char() {
            if c == '\n' {
                break;
            }
            result.push(self.next_char().unwrap());
        }

        Token::Comment(result.trim().to_string())
    }

    /// ğŸ”¹ ë¸”ë¡ ì£¼ì„ íŒŒì‹± (ì˜ˆ: /* ... */)
    fn read_block_comment(&mut self) -> Token {
        let mut result = String::new();

        while let Some(c) = self.next_char() {
            if c == '*' {
                if let Some(&'/') = self.peek_char() {
                    self.next_char(); // consume '/'
                    break;
                }
            }
            result.push(c);
        }

        Token::Comment(result.trim().to_string())
    }

    /// ğŸ”¹ ì…ë ¥ì—ì„œ í† í° í•˜ë‚˜ íŒŒì‹±
    pub fn next_token(&mut self) -> Token {
        while let Some(c) = self.next_char() {
            match c {
                '/' => {
                    if let Some(&'/') = self.peek_char() {
                        self.next_char(); // consume second '/'
                        return self.read_line_comment();
                    } else if let Some(&'*') = self.peek_char() {
                        self.next_char(); // consume '*'
                        return self.read_block_comment();
                    } else {
                        return Token::Unknown(c);
                    }
                }

                '"' => return self.read_string(),
                '@' => return self.read_field(),
                '+' => return Token::Plus,
                '=' => return Token::Equal,
                ';' => return Token::Semicolon,
                '{' => return Token::LBrace,
                '}' => return Token::RBrace,
                '.' => return Token::Dot,
                '(' => return Token::LParen,
                ')' => return Token::RParen,
                c if c.is_whitespace() => continue,
                c if c.is_alphanumeric() => return self.read_identifier_or_number(c),
                other => return Token::Unknown(other),
            }
        }

        Token::EOF
    }

    /// ğŸ”¹ ì „ì²´ ì…ë ¥ì„ í† í° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    pub fn tokenize(&mut self) -> Vec<Token> {
        let mut tokens = Vec::new();

        loop {
            let token = self.next_token();
            if token == Token::EOF {
                break;
            }
            tokens.push(token);
        }

        tokens
    }
}
