//! âœ… DSLìš© Lexer
//!
//! ì´ ëª¨ë“ˆì€ ì‚¬ìš©ì ì •ì˜ DSL ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” Tokenìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ì—­í• ì„ í•œë‹¤.
//! ì˜ˆ: input/output/transform/print ë“±ì˜ í‚¤ì›Œë“œ, ë¬¸ìì—´, ì‹ë³„ì, ì—°ì‚°ì ë“±ì„ ì¸ì‹í•œë‹¤.

use std::iter::Peekable;
use std::str::Chars;

/// âœ… DSLì—ì„œ ì‚¬ìš©í•  ëª¨ë“  í† í° ì •ì˜
#[derive(Debug, Clone, PartialEq)]
pub enum Token {
    // í‚¤ì›Œë“œë“¤
    Input, Output, Transform, Print,

    // ê°’ ë˜ëŠ” ì°¸ì¡°
    StringLiteral(String),      // ì˜ˆ: "sample.jsonl"
    Identifier(String),         // ì˜ˆ: line, suffix ë“±
    Field(String),              // ì˜ˆ: @ë¬¸ì œ

    Number(usize),              // ì˜ˆ: 42

    // ì—°ì‚°ì ë° êµ¬ë¶„ì
    Plus,                       // +
    Equal,                      // =
    Semicolon,                  // ;
    LBrace,                  // {
    RBrace,                 // }
    Dot,                        // . (í•¨ìˆ˜ í˜¸ì¶œ êµ¬ë¶„ì)
    LParen,                     // ( (í•¨ìˆ˜ í˜¸ì¶œ ì‹œì‘)
    RParen,                     // ) (í•¨ìˆ˜ í˜¸ì¶œ ì¢…ë£Œ)

    // ì˜ˆì™¸ ë° ì¢…ë£Œ
    Unknown(char),              // ì •ì˜ë˜ì§€ ì•Šì€ ë¬¸ì
    EOF,                        // ì…ë ¥ ì¢…ë£Œ
}


/// âœ… Lexer êµ¬ì¡°ì²´
/// ì…ë ¥ ë¬¸ìì—´ì„ í•œ ê¸€ìì”© ìˆœíšŒí•˜ë©° Tokenì„ ìƒì„±í•¨
pub struct Lexer<'a> {
    input: Peekable<Chars<'a>>, // Peekableë¡œ ì• ê¸€ì í™•ì¸ ê°€ëŠ¥í•˜ê²Œ ì²˜ë¦¬
}

impl<'a> Lexer<'a> {
    /// ğŸ”¹ ìƒì„±ì
    pub fn new(source: &'a str) -> Self {
        Self {
            input: source.chars().peekable(),
        }
    }

    /// ğŸ”¹ ë‹¤ìŒ ë¬¸ì ë°˜í™˜ (consume)
    fn next_char(&mut self) -> Option<char> {
        self.input.next()
    }

    /// ğŸ”¹ ë‹¤ìŒ ë¬¸ìë¥¼ ë¯¸ë¦¬ ë³´ê¸° (ì†Œë¹„í•˜ì§€ ì•ŠìŒ)
    fn peek_char(&mut self) -> Option<&char> {
        self.input.peek()
    }

    /// ğŸ”¹ ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì½ê¸°: "..."
    fn read_string(&mut self) -> Token {
        let mut result = String::new();

        while let Some(c) = self.next_char() {
            if c == '"' {
                break;
            }
            result.push(c);
        }

        Token::StringLiteral(result)
    }

    /// ğŸ”¹ @í•„ë“œëª… ì²˜ë¦¬: @ì´í›„ì˜ ì‹ë³„ì ì¶”ì¶œ
    fn read_field(&mut self) -> Token {
        let mut name = String::new();

        while let Some(&c) = self.peek_char() {
            if c.is_alphanumeric() || c == '_' {
                name.push(self.next_char().expect("Lexer error: failed to read character after '@'"));
            } else {
                break;
            }
        }

        Token::Field(name)
    }

    /// ğŸ”¹ ì‹ë³„ì ë˜ëŠ” ìˆ«ì ë˜ëŠ” í‚¤ì›Œë“œ íŒë³„
    fn read_identifier_or_number(&mut self, first_char: char) -> Token {
        let mut value = String::new();
        value.push(first_char);

        while let Some(&c) = self.peek_char() {
            if c.is_alphanumeric() || c == '_' {
                value.push(self.next_char().expect("Lexer error: failed to read identifier character"));
            } else {
                break;
            }
        }

        match value.as_str() {
            // í‚¤ì›Œë“œ ìš°ì„  ì²˜ë¦¬
            "input" => Token::Input,
            "output" => Token::Output,
            "transform" => Token::Transform,
            "print" => Token::Print,
            _ => {
                // ìˆ«ì ë¦¬í„°ëŸ´ íŒë³„
                if let Ok(num) = value.parse::<usize>() {
                    Token::Number(num)
                } else {
                    Token::Identifier(value)
                }
            }
        }
    }

    /// ğŸ”¹ ì…ë ¥ìœ¼ë¡œë¶€í„° í† í° í•˜ë‚˜ ë°˜í™˜
    pub fn next_token(&mut self) -> Token {
        while let Some(c) = self.next_char() {
            match c {
                '"' => return self.read_string(),
                '@' => return self.read_field(),
                '+' => return Token::Plus,
                '=' => return Token::Equal,
                ';' => return Token::Semicolon,
                '{' => return Token::LBrace,
                '}' => return Token::RBrace,
                '.' => return Token::Dot,
                '(' => return Token::LParen,
                ')' => return Token::RParen,
            
                c if c.is_whitespace() => continue,
                c if c.is_alphanumeric() => return self.read_identifier_or_number(c),
            
                other => return Token::Unknown(other),
            }            
        }

        Token::EOF
    }

    /// ğŸ”¹ ì „ì²´ ì…ë ¥ì„ ìˆœíšŒí•˜ë©° í† í° ë¦¬ìŠ¤íŠ¸ ìƒì„±
    pub fn tokenize(&mut self) -> Vec<Token> {
        let mut tokens = Vec::new();

        loop {
            let token = self.next_token();
            if token == Token::EOF {
                break;
            }
            tokens.push(token);
        }

        tokens
    }
}
