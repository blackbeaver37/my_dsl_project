//! âœ… DSLìš© Lexer
//!
//! ì´ ëª¨ë“ˆì€ ì‚¬ìš©ì ì •ì˜ DSL ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” Tokenìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ì—­í• ì„ í•œë‹¤.
//! ì˜ˆ: input/output/update/print ë“±ì˜ í‚¤ì›Œë“œ, ë¬¸ìì—´, ì‹ë³„ì, ì—°ì‚°ì ë“±ì„ ì¸ì‹í•œë‹¤.

use std::iter::Peekable;
use std::str::Chars;

/// âœ… DSLì—ì„œ ì‚¬ìš©í•  ëª¨ë“  í† í° ì •ì˜
#[derive(Debug, Clone, PartialEq)]
pub enum Token {
    // í‚¤ì›Œë“œë“¤
    Input,                  // `input` ëª…ë ¹ì–´
    Output,                 // `output` ëª…ë ¹ì–´
    Update,                 // `update` ëª…ë ¹ì–´
    Print,                  // `print` ëª…ë ¹ì–´

    // ê°’ ë˜ëŠ” ì°¸ì¡°
    StringLiteral(String),  // ë¬¸ìì—´ (ì˜ˆ: "sample.jsonl")
    Identifier(String),     // ì¼ë°˜ ì‹ë³„ì (ì˜ˆ: line, data_title ë“±)
    Field(String),          // @í•„ë“œëª… (ì˜ˆ: @ë¬¸ì œ, @ê³¼ëª©)

    Number(usize),          // ìˆ«ì ë¦¬í„°ëŸ´ (ì˜ˆ: 1, 42 ë“±)

    // ì—°ì‚°ì ë° êµ¬ë¶„ì
    Plus,                   // `+` (ë¬¸ìì—´ ì—°ê²° ì—°ì‚°ì)
    Equal,                  // `=` (ëŒ€ì… ì—°ì‚°ì)
    Semicolon,              // `;` (ëª…ë ¹ì–´ êµ¬ë¶„)
    LeftBrace,              // `{` (update ë¸”ë¡ ì‹œì‘)
    RightBrace,             // `}` (update ë¸”ë¡ ì¢…ë£Œ)

    // ì˜ˆì™¸ ë° ì¢…ë£Œ
    Unknown(char),          // ì •ì˜ë˜ì§€ ì•Šì€ ë¬¸ì
    EOF,                    // ì…ë ¥ ì¢…ë£Œ
}

/// âœ… Lexer êµ¬ì¡°ì²´
/// ì…ë ¥ ë¬¸ìì—´ì„ í•œ ê¸€ìì”© ìˆœíšŒí•˜ë©° Tokenì„ ìƒì„±í•¨
pub struct Lexer<'a> {
    input: Peekable<Chars<'a>>, // Peekableë¡œ ì• ê¸€ì í™•ì¸ ê°€ëŠ¥í•˜ê²Œ ì²˜ë¦¬
}

impl<'a> Lexer<'a> {
    /// ğŸ”¹ ìƒì„±ì
    pub fn new(source: &'a str) -> Self {
        Self {
            input: source.chars().peekable(),
        }
    }

    /// ğŸ”¹ ë‹¤ìŒ ë¬¸ì ë°˜í™˜ (consume)
    fn next_char(&mut self) -> Option<char> {
        self.input.next()
    }

    /// ğŸ”¹ ë‹¤ìŒ ë¬¸ìë¥¼ ë¯¸ë¦¬ ë³´ê¸° (ì†Œë¹„í•˜ì§€ ì•ŠìŒ)
    fn peek_char(&self) -> Option<&char> {
        self.input.peek()
    }

    /// ğŸ”¹ ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì½ê¸°: "..."
    fn read_string(&mut self) -> Token {
        let mut result = String::new();

        while let Some(c) = self.next_char() {
            if c == '"' {
                break;
            }
            result.push(c);
        }

        Token::StringLiteral(result)
    }

    /// ğŸ”¹ @í•„ë“œëª… ì²˜ë¦¬: @ì´í›„ì˜ ì‹ë³„ì ì¶”ì¶œ
    fn read_field(&mut self) -> Token {
        let mut name = String::new();

        while let Some(&c) = self.peek_char() {
            if c.is_alphanumeric() || c == '_' {
                name.push(self.next_char().expect("Lexer error: failed to read character after '@'"));
            } else {
                break;
            }
        }

        Token::Field(name)
    }

    /// ğŸ”¹ ì‹ë³„ì ë˜ëŠ” ìˆ«ì ë˜ëŠ” í‚¤ì›Œë“œ íŒë³„
    fn read_identifier_or_number(&mut self, first_char: char) -> Token {
        let mut value = String::new();
        value.push(first_char);

        while let Some(&c) = self.peek_char() {
            if c.is_alphanumeric() || c == '_' {
                value.push(self.next_char().expect("Lexer error: failed to read identifier character"));
            } else {
                break;
            }
        }

        match value.as_str() {
            // í‚¤ì›Œë“œ ìš°ì„  ì²˜ë¦¬
            "input" => Token::Input,
            "output" => Token::Output,
            "update" => Token::Update,
            "print" => Token::Print,
            _ => {
                // ìˆ«ì ë¦¬í„°ëŸ´ íŒë³„
                if let Ok(num) = value.parse::<usize>() {
                    Token::Number(num)
                } else {
                    Token::Identifier(value)
                }
            }
        }
    }

    /// ğŸ”¹ ì…ë ¥ìœ¼ë¡œë¶€í„° í† í° í•˜ë‚˜ ë°˜í™˜
    pub fn next_token(&mut self) -> Token {
        while let Some(c) = self.next_char() {
            match c {
                '"' => return self.read_string(),
                '@' => return self.read_field(),
                '+' => return Token::Plus,
                '=' => return Token::Equal,
                ';' => return Token::Semicolon,
                '{' => return Token::LeftBrace,
                '}' => return Token::RightBrace,

                c if c.is_whitespace() => continue,
                c if c.is_alphanumeric() => return self.read_identifier_or_number(c),

                other => return Token::Unknown(other),
            }
        }

        Token::EOF
    }

    /// ğŸ”¹ ì „ì²´ ì…ë ¥ì„ ìˆœíšŒí•˜ë©° í† í° ë¦¬ìŠ¤íŠ¸ ìƒì„±
    pub fn tokenize(&mut self) -> Vec<Token> {
        let mut tokens = Vec::new();

        loop {
            let token = self.next_token();
            if token == Token::EOF {
                break;
            }
            tokens.push(token);
        }

        tokens
    }
}
